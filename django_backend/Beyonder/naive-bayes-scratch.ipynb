{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a6f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd5fd8ed-d18d-43e3-b8e8-677274178d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_classifier import NaiveBayesClassifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f6079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('processed_train_data.csv')\n",
    "test = pd.read_csv('processed_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39c9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "train.dropna(inplace=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "additional_stop_words = {'u', 'im'}\n",
    "stop_words |= additional_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2806a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Dictionary for common typos and slangs\n",
    "typos_slangs = {\n",
    "    \"dont\": \"don't\",\n",
    "    \"cant\": \"can't\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    # Add more typos and slangs as needed\n",
    "}\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Use raw strings (prefix with r) to prevent SyntaxWarnings\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Replace typos and slangs\n",
    "    for typo, correction in typos_slangs.items():\n",
    "        text = text.replace(typo, correction)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tagged_tokens = nltk.pos_tag(tokens)\n",
    "    lemmatized_tokens = [\n",
    "        lemmatizer.lemmatize(token, pos=pos[0].lower()) if pos[0].lower() in ['n', 'v', 'a']\n",
    "        else lemmatizer.lemmatize(token)\n",
    "        for token, pos in tagged_tokens\n",
    "    ]\n",
    "\n",
    "    # Handle negations\n",
    "    processed_tokens = []\n",
    "    negation = False\n",
    "    for token in lemmatized_tokens:\n",
    "        if token in {'not', 'no', 'never', 'neither', 'nor', \"cannot\", \"won't\"}:\n",
    "            negation = True\n",
    "        elif negation:\n",
    "            token = 'not_' + token\n",
    "            negation = False\n",
    "        processed_tokens.append(token)\n",
    "    \n",
    "    processed_text = ' '.join([word for word in processed_tokens if word not in stop_words])\n",
    "    \n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d3ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(clean_text)\n",
    "test['text'] = test['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6013a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64ce7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "X_train = train['text']\n",
    "X_test = test['text']\n",
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0526acf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            id respond go\n",
       "1                                  sooo sad miss san diego\n",
       "2                                                bos bully\n",
       "3                                    interview leave alone\n",
       "4                      son couldnt put release already buy\n",
       "                               ...                        \n",
       "27475    wish could come see u denver husband lose job ...\n",
       "27476    ive wonder rake client make clear net nt force...\n",
       "27477    yay good enjoy break probably need hectic week...\n",
       "27478                                                worth\n",
       "27479                           flirt go atg smile yay hug\n",
       "Name: text, Length: 27413, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6837c793",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nb_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# # Training Naive Bayes Classifier\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# nb_classifier = NaiveBayesClassifier()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mnb_classifier\u001b[49m.train(X_train, y_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'nb_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "# # Training Naive Bayes Classifier\n",
    "# nb_classifier = NaiveBayesClassifier()\n",
    "nb_classifier.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = nb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Accuracy (Naive Bayes from scratch): \", accuracy * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dcd2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example predictions\n",
    "input_sentences = [\"highly appreciated\", \"hell\"] \n",
    "for input_sentence in input_sentences:\n",
    "    processed_input = clean_text(input_sentence)\n",
    "    predicted_label = nb_classifier.predict([processed_input])[0]\n",
    "    print(f\"Input: {input_sentence}, Processed Input: {processed_input}, Predicted class label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6691df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('naive_b_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_classifier, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfbfc88-d3ac-4dd6-b49e-509d00a8214b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
